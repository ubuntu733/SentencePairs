{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetL = []\n",
    "with open(\"../data/data_tfkdl.txt\", \"rb\") as reader:\n",
    "    for line in reader:\n",
    "        line = line.decode(\"utf-8\")\n",
    "        datasetL.append(int(line[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===dataset length is=== 102477\n",
      "===example of the dataset label=== [1 0 0 0 0 0 0 0 0 0]\n",
      "========= 18685\n",
      "========= [array([ True, False, False, ..., False, False, False])]\n"
     ]
    }
   ],
   "source": [
    "datasetL = np.array(datasetL)\n",
    "print(\"===dataset length is===\", len(datasetL))\n",
    "print(\"===example of the dataset label===\", datasetL[:10])\n",
    "print(\"=========\", len(datasetL[datasetL == 1]))\n",
    "print(\"=========\", [datasetL == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datamatrix = np.load(\"../data/datamatrix.npz.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer = pickle.load(open(\"../data/dict_vectorizer.model\", \"rb\"))\n",
    "dict_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102477, 62)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.23809488,  2.6       ,  0.8125    , ...,  0.41102522,\n",
       "        22.        , 15.        ],\n",
       "       [-4.00000046, -3.11111111, -5.6       , ...,  0.34216169,\n",
       "        17.        , 12.        ],\n",
       "       [-0.66666716, -0.71428571, -0.625     , ...,  0.07804434,\n",
       "        18.        , 12.        ],\n",
       "       ...,\n",
       "       [-2.88888938, -2.6       , -3.25      , ...,  0.82995183,\n",
       "        20.        , 13.        ],\n",
       "       [-2.16666715, -1.85714286, -2.6       , ...,  0.17947173,\n",
       "        14.        , 10.        ],\n",
       "       [-2.0000005 , -1.83333333, -2.2       , ...,  0.24473729,\n",
       "        14.        ,  7.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datamatrix.shape)\n",
    "datamatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_indices(label):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pos_indices = []\n",
    "    neg_indices = []\n",
    "    for index, label in enumerate(label):\n",
    "        if label == 1:\n",
    "            pos_indices.append(index)\n",
    "        else:\n",
    "            neg_indices.append(index)\n",
    "    return pos_indices, neg_indices\n",
    "\n",
    "def split(datasetM, label, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    split the dataset into train test, 10% for test 10% for valid(make the train test label )\n",
    "    \"\"\"\n",
    "    pos_indices, neg_indices = get_label_indices(label)\n",
    "    \n",
    "    pos_permutaion_indices = np.random.permutation(len(pos_indices))\n",
    "    neg_permutation_indices = np.random.permutation(len(neg_indices))\n",
    "    \n",
    "    train_pos_len = int(len(pos_indices) * train_ratio)\n",
    "    train_neg_len = int(len(neg_indices) * train_ratio)\n",
    "    \n",
    "    train_pos_indices = pos_permutaion_indices[:train_pos_len]\n",
    "    train_neg_indices = neg_permutation_indices[:train_neg_len]\n",
    "    train_indices = np.concatenate((train_pos_indices, train_neg_indices))\n",
    "    np.random.shuffle(train_indices)\n",
    "    train_datasetM = datasetM[train_indices]\n",
    "    train_datasetL = label[train_indices]\n",
    "    \n",
    "    test_pos_indices =pos_permutaion_indices[train_pos_len:]\n",
    "    test_neg_indices = neg_permutation_indices[train_neg_len:]\n",
    "    test_indices = np.concatenate((test_pos_indices, test_neg_indices))\n",
    "    np.random.shuffle(test_indices)\n",
    "    test_datasetM = datasetM[test_indices]\n",
    "    test_datasetL = label[test_indices]\n",
    "    \n",
    "    return train_datasetM, train_datasetL, test_datasetM, test_datasetL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===train dataset shape==== (81981, 62)\n",
      "===test dataset shape==== (20496, 62)\n"
     ]
    }
   ],
   "source": [
    "train_datasetM, train_datasetL, test_datasetM, test_datasetL = split(datamatrix, datasetL)\n",
    "\n",
    "assert(train_datasetM.shape[0] == len(train_datasetL))\n",
    "assert(test_datasetM.shape[0] == len(test_datasetL))\n",
    "\n",
    "print(\"===train dataset shape====\", train_datasetM.shape)\n",
    "print(\"===test dataset shape====\", test_datasetM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_datasetM, train_datasetL)\n",
    "dtest = xgb.DMatrix(test_datasetM, test_datasetM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xueyunzhe/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# specify parameters via map\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=500, \n",
    "                                       silent=True, objective='binary:logistic', booster='gbtree', \n",
    "                                       n_jobs=1, nthread=None, gamma=0, \n",
    "                                       min_child_weight=5, max_delta_step=0, subsample=1, \n",
    "                                       colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, \n",
    "                                       reg_lambda=1, scale_pos_weight=4, \n",
    "                                       base_score=0.5, random_state=0, seed=None, missing=None)\n",
    "bst = xgb_classifier.fit(train_datasetM, train_datasetL)\n",
    "# make prediction\n",
    "preds = bst.predict(test_datasetM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_label = preds >= 0.5\n",
    "pred_label = pred_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.75      0.82     16599\n",
      "          1       0.38      0.67      0.48      3897\n",
      "\n",
      "avg / total       0.81      0.73      0.75     20496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_datasetL, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
