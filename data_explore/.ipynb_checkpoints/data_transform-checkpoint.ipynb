{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.764 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"../data/dict\")\n",
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return \"\".join(ss)\n",
    "\n",
    "def change_sentence(sentence):\n",
    "    # 全角转半角\n",
    "    sentence = strQ2B(sentence)\n",
    "    \n",
    "    # 去除标点符号\n",
    "    sentence = sentence.replace(\",\", \"\")\n",
    "    sentence = sentence.replace(\"，\", \"\")\n",
    "    sentence = sentence.replace(\".\", \"\")\n",
    "    sentence = sentence.replace(\"。\", \"\")\n",
    "    sentence = sentence.replace(\"?\", \"\")\n",
    "    sentence = sentence.replace(\"？\", \"\")\n",
    "    sentence = sentence.replace(\"!\", \"\")\n",
    "    \n",
    "    # 替换某些词语\n",
    "    sentence = sentence.replace(\"借贝\", \"借呗\")\n",
    "    sentence = sentence.replace(\"花贝\", \"花呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁借呗\", \"借呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁花呗\", \"花呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁花呗\", \"花呗\")\n",
    "    sentence = sentence.replace(\"整么\", \"怎么\")\n",
    "    sentence = sentence.replace(\"冻解\", \"冻结\")\n",
    "    sentence = sentence.replace(\"撤掉\", \"撤销\")\n",
    "    sentence = sentence.replace(\"提额\", \"提高额度\")\n",
    "    sentence = sentence.replace(\"买机票\", \"订机票\")\n",
    "    \n",
    "    # 将***替换成N\n",
    "    sentence = re.sub(r'[*]+', \"N\", sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def seg_dataset(dataset_path, save_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(dataset_path, sep=\"\\t\", header=None)\n",
    "    \n",
    "    dataset.columns = [\"label\", \"sent1\", \"sent2\", \"id\"]\n",
    "    \n",
    "    print(dataset.head(2))\n",
    "    \n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \"\".join(str(x).split()))\n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: change_sentence(x))\n",
    "    \n",
    "    #dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=False)))\n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=True)))\n",
    "    \n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: str(x).replace(\" \", \"\"))\n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: change_sentence(x))\n",
    "    #dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=False)))\n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=True)))\n",
    "    \n",
    "    dataset.to_csv(save_path, sep=\"\\t\", header=False, index=False)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                   sent1          sent2      id\n",
      "0      0  为什么 我 的 花呗 额度 总是 无法 提高     都 是 用 花呗 的  100209\n",
      "1      0         花呗 冻结 后要 怎样才能 用  花呗 冻结 了 怎样 还款   57509\n",
      "   label                                            sent1  \\\n",
      "0      0                      支付宝 在 不同 手机 登录 会 影响 借呗 使用 吗   \n",
      "1      0  花呗 逾期 一个月 刚用 不 知道 这个 月 号 还 的 要 到 什么 时候 才能 用 很 急   \n",
      "\n",
      "                           sent2     id  \n",
      "0            网上 贷款 会 不会 影响 借呗 信用  54642  \n",
      "1  我 现在 刚借 的 花呗 要 下个月 最迟 什么 时候 还  50309  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_dataset(\"../data/ori_data/train.csv\", \"../data/ori_data/train_process_hmm.csv\")\n",
    "seg_dataset(\"../data/ori_data/dev.csv\", \"../data/ori_data/dev_process_hmm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                   sent1          sent2      id\n",
      "0      0  为什么 我 的 花呗 额度 总是 无法 提高     都 是 用 花呗 的  100209\n",
      "1      0         花呗 冻结 后要 怎样才能 用  花呗 冻结 了 怎样 还款   57509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_dataset(\"../data/ori_data/complete.csv\", \"../data/ori_data/complete_process_hmm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the dev dataset into origin\n",
    "def transform2origin(dataset_path, origin_dev_path):\n",
    "    \"\"\"\n",
    "    :param dataset_path\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(dataset_path, sep=\"\\t\", header=None)\n",
    "    \n",
    "    dataset.columns = [\"label\", \"sent1\", \"sent2\", \"id\"]\n",
    "    \n",
    "    new_dataset = pd.DataFrame()\n",
    "    new_dataset[\"id\"] = dataset[\"id\"]\n",
    "    new_dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \"\".join(x.split()))\n",
    "    new_dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \"\".join(x.split()))\n",
    "    \n",
    "    new_dataset.to_csv(origin_dev_path, sep=\"\\t\", header=False, index=False)\n",
    "    \n",
    "    return dataset[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = transform2origin(\"../data/ori_data/dev.csv\", \"../data/ori_data/origin.dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with open(\"/home/xueyunzhe/examplex_learning/matching/SentencePairs/submit/vec_feat_xgb_test/test_pred\", \"r\") as reader:\n",
    "    for line in reader:\n",
    "        lineno, label_ = line.strip().split(\"\\t\")\n",
    "        preds.append(int(label_))\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got '1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b2d25a13a845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/xueyunzhe/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xueyunzhe/anaconda3/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xueyunzhe/anaconda3/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xueyunzhe/anaconda3/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 244\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SparseSeries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got '1'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
