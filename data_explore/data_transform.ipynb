{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.764 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"../data/dict\")\n",
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全角空格直接转换\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return \"\".join(ss)\n",
    "\n",
    "def change_sentence(sentence):\n",
    "    # 全角转半角\n",
    "    sentence = strQ2B(sentence)\n",
    "    \n",
    "    # 去除标点符号\n",
    "    sentence = sentence.replace(\",\", \"\")\n",
    "    sentence = sentence.replace(\"，\", \"\")\n",
    "    sentence = sentence.replace(\".\", \"\")\n",
    "    sentence = sentence.replace(\"。\", \"\")\n",
    "    sentence = sentence.replace(\"?\", \"\")\n",
    "    sentence = sentence.replace(\"？\", \"\")\n",
    "    sentence = sentence.replace(\"!\", \"\")\n",
    "    \n",
    "    # 替换某些词语\n",
    "    sentence = sentence.replace(\"借贝\", \"借呗\")\n",
    "    sentence = sentence.replace(\"花贝\", \"花呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁借呗\", \"借呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁花呗\", \"花呗\")\n",
    "    sentence = sentence.replace(\"蚂蚁花呗\", \"花呗\")\n",
    "    sentence = sentence.replace(\"整么\", \"怎么\")\n",
    "    sentence = sentence.replace(\"冻解\", \"冻结\")\n",
    "    sentence = sentence.replace(\"撤掉\", \"撤销\")\n",
    "    sentence = sentence.replace(\"提额\", \"提高额度\")\n",
    "    sentence = sentence.replace(\"买机票\", \"订机票\")\n",
    "    \n",
    "    # 将***替换成N\n",
    "    sentence = re.sub(r'[*]+', \"N\", sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def seg_dataset(dataset_path, save_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(dataset_path, sep=\"\\t\", header=None)\n",
    "    \n",
    "    dataset.columns = [\"label\", \"sent1\", \"sent2\", \"id\"]\n",
    "    \n",
    "    print(dataset.head(2))\n",
    "    \n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \"\".join(str(x).split()))\n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: change_sentence(x))\n",
    "    \n",
    "    #dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=False)))\n",
    "    dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=True)))\n",
    "    \n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: str(x).replace(\" \", \"\"))\n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: change_sentence(x))\n",
    "    #dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=False)))\n",
    "    dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \" \".join(jieba.cut(x, HMM=True)))\n",
    "    \n",
    "    dataset.to_csv(save_path, sep=\"\\t\", header=False, index=False)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                   sent1          sent2      id\n",
      "0      0  为什么 我 的 花呗 额度 总是 无法 提高     都 是 用 花呗 的  100209\n",
      "1      0         花呗 冻结 后要 怎样才能 用  花呗 冻结 了 怎样 还款   57509\n",
      "   label                                            sent1  \\\n",
      "0      0                      支付宝 在 不同 手机 登录 会 影响 借呗 使用 吗   \n",
      "1      0  花呗 逾期 一个月 刚用 不 知道 这个 月 号 还 的 要 到 什么 时候 才能 用 很 急   \n",
      "\n",
      "                           sent2     id  \n",
      "0            网上 贷款 会 不会 影响 借呗 信用  54642  \n",
      "1  我 现在 刚借 的 花呗 要 下个月 最迟 什么 时候 还  50309  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_dataset(\"../data/ori_data/train.csv\", \"../data/ori_data/train_process_hmm.csv\")\n",
    "seg_dataset(\"../data/ori_data/dev.csv\", \"../data/ori_data/dev_process_hmm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                   sent1          sent2      id\n",
      "0      0  为什么 我 的 花呗 额度 总是 无法 提高     都 是 用 花呗 的  100209\n",
      "1      0         花呗 冻结 后要 怎样才能 用  花呗 冻结 了 怎样 还款   57509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_dataset(\"../data/ori_data/complete.csv\", \"../data/ori_data/complete_process_hmm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the dev dataset into origin\n",
    "def transform2origin(dataset_path, origin_dev_path):\n",
    "    \"\"\"\n",
    "    :param dataset_path\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(dataset_path, sep=\"\\t\", header=None)\n",
    "    \n",
    "    dataset.columns = [\"label\", \"sent1\", \"sent2\", \"id\"]\n",
    "    \n",
    "    new_dataset = pd.DataFrame()\n",
    "    new_dataset[\"id\"] = dataset[\"id\"]\n",
    "    new_dataset[\"sent1\"] = dataset[\"sent1\"].apply(lambda x: \"\".join(x.split()))\n",
    "    new_dataset[\"sent2\"] = dataset[\"sent2\"].apply(lambda x: \"\".join(x.split()))\n",
    "    \n",
    "    new_dataset.to_csv(origin_dev_path, sep=\"\\t\", header=False, index=False)\n",
    "    \n",
    "    return dataset[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = transform2origin(\"../data/ori_data/dev.csv\", \"../data/ori_data/origin.dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with open(\"/home/xueyunzhe/examplex_learning/matching/SentencePairs/submit/vec_feat_xgb_test/test_pred\", \"r\") as reader:\n",
    "    for line in reader:\n",
    "        lineno, label_ = line.strip().split(\"\\t\")\n",
    "        preds.append(int(label_))\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.83      0.86     16751\n",
      "          1       0.43      0.57      0.49      3744\n",
      "\n",
      "avg / total       0.81      0.78      0.79     20495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
